* Inbox
* DONE git 'er done [5/5]
CLOSED: [2025-08-26 Tue 21:54]
** DONE find the date posted along with other data
CLOSED: [2025-08-26 Tue 14:06]
:LOGBOOK:
CLOCK: [2025-08-26 Tue 09:54]--[2025-08-26 Tue 14:06] =>  4:12
:END:
[[file:/Users/oldbones/Projects/job_hunt/modules/scrapers/parser_creation.py::def find_css_selectors(self, url, html_content):]]
*** DONE database column
CLOSED: [2025-08-26 Tue 14:06]
** DONE create a score table
CLOSED: [2025-08-26 Tue 21:27]
*** columns
**** score
**** explanation
**** job_id
**** resume_id
*** KILL score as JSON
regex is good enought
CLOSED: [2025-08-26 Tue 21:27]
** KILL score_resume.py should show ascii table with list of job descriptions, prompting the use to pick and ID.  After they select via typing id then another table with resume comes up and they select id again.
Meh.
CLOSED: [2025-08-26 Tue 21:54]
** DONE [#B] create resume table
CLOSED: [2025-08-26 Tue 20:05]
this table will correlate to the score

** DONE [#B] add docker compose and potentially a Dockerfile
CLOSED: [2025-08-26 Tue 20:05]
[[file:/Users/oldbones/Projects/job_hunt/notes.org]]
* DONE Some lib files don't need the command line. identify and remove CLOSED: [2025-08-26 Tue 21:59]

[[file:/Users/oldbones/Projects/job_hunt/lib/parsers/generic.py::"description": description,]]
* DONE Make a library that spins up a playwright browser. lib/browser.py
CLOSED: [2025-01-27 Mon]
* DONE make a file called cli/extract_job.py
CLOSED: [2025-01-27 Mon]
* DONE cli/extract_job.py spins up the playwrite browser
CLOSED: [2025-01-27 Mon]
* DONE cli/extract_job.py passes in url, username, password  client into the lib/browser.py instantiation
CLOSED: [2025-01-27 Mon]
* DONE browser goes to url and if it does not 301/302 it returns the DOM as a string
CLOSED: [2025-01-27 Mon]
* TODO finish linked in test by moving into a service.
* TODO Define a service
Service instantiates a URL of a job posting
it will attempt to visit the url and get the contents
if it is behind a login, it will log in.
if the actual job application/description is somewhere else, it will track that down as well
** TODO It has an additional service of allowing css selectors to circumvent having to go to chatgpt all the time
* TODO The easy way to record a job posting
navigate to the unrestricted job
scrape then parse, alternatively
